{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi-3 Mini Instruct\n",
    "\n",
    "In this example, we will see how you can run Cohere Command R+ to consume predictions using the [Azure AI model infernece API](https://aka.ms/azureai/modelinference) along with the package `azure-ai-inference` SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "The following functions help to print the streaming response of a request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(response):\n",
    "    \"\"\"\n",
    "    Prints the response from the service as it is received using\n",
    "    streaming. A delay is added to simulate a real-time conversation.\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    for update in response:\n",
    "        if update.choices[0].delta.content:\n",
    "            print(update.choices[0].delta.content, end=\"\")\n",
    "            # Simulate a delay in the conversation.\n",
    "            time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat completions\n",
    "\n",
    "The following example shows how you can run the chat completions API using the `azure-ai-inference` SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "model = ChatCompletionsClient(\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    token = os.environ[\"GITHUB_TOKEN\"],\n",
    "    model_name=\"Phi-3-mini-4k-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the first request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The question seems to be asking about the number of languages represented in a specific word. However, without specifying a particular word, it's impossible to provide an exact answer. Languages are systems of communication used by people, and a single word can belong to multiple languages depending on its origin, usage, and context.\n",
      "\n",
      "For example, the word \"hello\" is primarily associated with English, but it has been adopted into many other languages with slight variations in spelling and pronunciation. Similarly, the word \"computer\" is primarily associated with English, but it has been adopted into other languages with slight variations in spelling and pronunciation.\n",
      "\n",
      "If you provide a specific word, I can help determine the number of languages it is associated with."
     ]
    }
   ],
   "source": [
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "\n",
    "response = model.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a helpful assistant\"),\n",
    "        UserMessage(content=\"How many languages are in the word?\"),\n",
    "    ],\n",
    "    temperature=0,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print_stream(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
